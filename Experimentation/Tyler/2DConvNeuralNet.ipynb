{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import pickle\n",
    "from helpers import *\n",
    "from ImageProcessing import *\n",
    "from PIL import Image\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_2D_patchNo_channels6 and Y_2D_patchNo_channels6\n",
      "X shape is (800, 400, 400, 3)\n",
      "Y shape is (800, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "filename_X = \"X_2D_patchNo_channels6\"\n",
    "filename_Y = \"Y_2D_patchNo_channels6\"\n",
    "\n",
    "infile_X = open(filename_X + \".pickle\",\"rb\")\n",
    "X = np.array(pickle.load(infile_X))\n",
    "infile_X.close()\n",
    "\n",
    "infile_Y = open(filename_Y + \".pickle\",\"rb\")\n",
    "Y = np.array(pickle.load(infile_Y))\n",
    "infile_Y.close()\n",
    "\n",
    "print(\"Loaded \" + filename_X + \" and \" + filename_Y)\n",
    "print(\"X shape is\", X.shape)\n",
    "print(\"Y shape is\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Xtest_2D_patch16_channels14.pickle\n",
      "X_test shape is (50, 38, 38, 14)\n"
     ]
    }
   ],
   "source": [
    "filename_X_test = \"Xtest_2D_patch16_channels14\"\n",
    "\n",
    "infile_X_test = open(filename_X_test + \".pickle\",\"rb\")\n",
    "X_test = pickle.load(infile_X_test)\n",
    "infile_X_test.close()\n",
    "print(\"Loaded \" + filename_X_test + \".pickle\")\n",
    "print(\"X_test shape is\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"1DModel_Aug\"\n",
    "\n",
    "model = keras.models.load_model(modelname + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Loading Tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (800, 400, 400, 3)\n",
      "y_train shape: (800, 400, 400, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.utils.normalize(X)\n",
    "del X\n",
    "\n",
    "Y[np.where(Y>=0.25)]=1\n",
    "Y[np.where(Y<0.25)]=0\n",
    "y_train = keras.utils.to_categorical(Y,num_classes=2)\n",
    "\n",
    "del Y\n",
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Initialization of a 2D convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 400, 400, 100)     400       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 200, 200, 5)       2005      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 5)       105       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 100, 100)     600       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 200, 200, 10)      4010      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200, 200, 100)     1100      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 400, 400, 5)       2005      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400, 400, 2)       12        \n",
      "=================================================================\n",
      "Total params: 10,237\n",
      "Trainable params: 10,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(100,activation='relu',input_shape=x_train.shape[1:4]))\n",
    "model.add(keras.layers.Conv2D(filters=5,kernel_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last',use_bias=True))\n",
    "model.add(keras.layers.Conv2D(filters=5,kernel_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last',use_bias=True))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Conv2DTranspose(filters=10,kernel_size=(2,2),strides=(2,2),activation='relu',padding='valid',data_format='channels_last',use_bias=True)),\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Conv2DTranspose(filters=5,kernel_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Initialization of optimization method, loss function and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_split=0.2, epochs=50,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3159c690>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.argmax(y_pred[0],axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
