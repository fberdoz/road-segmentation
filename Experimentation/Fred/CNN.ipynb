{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxR5rbti2VV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, re\n",
    "from PIL import Image                                 #create image from array\n",
    "from datetime import datetime                         #date for submission file\n",
    "from  scipy import ndimage\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "\n",
    "# CNN libraries (keras)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vU5YEHpi2Vc"
   },
   "outputs": [],
   "source": [
    "SEED = 34342\n",
    "PATCH_SIZE = 16\n",
    "NUMBER_TRAIN_IMG = 100 # max 100\n",
    "ROOT = \"./\"\n",
    "DATA_ROOT_DIR = ROOT+ \"Datasets/\"\n",
    "SUBMISSION_DIR= ROOT + \"Submissions/\"\n",
    "PREDICTION_DIR= ROOT + \"Predictions/\"\n",
    "CONTEXT = 16\n",
    "NB_CLASSES = 2\n",
    "NB_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "np.random.seed(SEED)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iLMJedei2Vf"
   },
   "source": [
    "### 1) Loading the set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lxSGRnKi2Vg"
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def LoadTrainingData(n_img, rootdir=\"Datasets/training/\", printnames=False):\n",
    "    \"\"\" Load the data from the root directory. (a total of n_img images) \"\"\"\n",
    "\n",
    "    image_dir = rootdir + \"images/\"\n",
    "    files = os.listdir(image_dir)\n",
    "\n",
    "    n = min(n_img, len(files)) # Load maximum 20 images\n",
    "    print(\"Loading \" + str(n) + \" train images...\")\n",
    "    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    gt_dir = rootdir + \"groundtruth/\"\n",
    "    print(\"Loading \" + str(n) + \" groundtruth images...\")\n",
    "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    if (printnames):\n",
    "        print(\"The loaded images are: \")\n",
    "        for i in range(n):\n",
    "            print(\"    - \" + files[i])\n",
    "    \n",
    "    return imgs, gt_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iow463wPi2Vj"
   },
   "outputs": [],
   "source": [
    "traindir = DATA_ROOT_DIR + \"training/\"\n",
    "imagedir = traindir + \"images/\"\n",
    "\n",
    "# list with all the available images name\n",
    "files = os.listdir(imagedir) \n",
    "\n",
    "n = NUMBER_TRAIN_IMG\n",
    "imgs, gt_imgs = LoadTrainingData(n, traindir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxIkMnAFi2Vm"
   },
   "source": [
    "### 2) Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIGMaRfXi2Vn",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The augmented data will present itself as follows: \n",
    "# [original img, 90° rotation, 180° rotation, 270° rotation, \n",
    "#  symmetry original img, sym 90° rot img, sym 180° rot img, sym 270° img]\n",
    "\n",
    "def DataAugmentation(imgs, gt_imgs, angles, sym=False, printinfo=False):\n",
    "    \"\"\"\n",
    "    Augments the data by rotating the image with the angles given in the list <angles>.\n",
    "    If <sym> is true, it also augments the the data with the images obtained by performing a\n",
    "    y axis symmetry.\n",
    "    \n",
    "    The augmented data will present itself as follows: \n",
    "        \n",
    "        [angles[1] rotations, ..., angles[end] rotations,\n",
    "        Y axis symmetry of the angles[1] rotations, ..., Y axis symmetry of the angles[end] rotations]\n",
    " \n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    \n",
    "    # Creating the augmented version of the images.\n",
    "    aug_imgs = []\n",
    "    aug_gt_imgs = []\n",
    "    \n",
    "    # Rotating the images and adding them to the augmented data list\n",
    "    for theta in angles:\n",
    "        if (printinfo):\n",
    "            print(\"Augmenting the data with the images rotated by\", theta , \"deg.\")\n",
    "        aug_imgs += [BuildRotatedImage(imgs[i], theta) for i in range(n)]\n",
    "        aug_gt_imgs += [BuildRotatedImage(gt_imgs[i], theta) for i in range(n)]  \n",
    "        \n",
    "    # Y symmetry of the images and adding them to the augmented dat list\n",
    "    if (sym):\n",
    "        if (printinfo):\n",
    "            print(\"Augmenting the data with the symmetries\")\n",
    "        n_tmp = len(aug_imgs)\n",
    "        aug_imgs += [np.flip(aug_imgs[i],1) for i in range(n_tmp)]\n",
    "        aug_gt_imgs += [np.flip(aug_gt_imgs[i],1) for i in range(n_tmp)]\n",
    "        \n",
    "    return aug_imgs, aug_gt_imgs\n",
    "\n",
    "    \n",
    "def BuildExtendedImage(img):\n",
    "    \"\"\" Create a 3x3 grid of the imput image by mirroring it at the boundaries\"\"\"\n",
    "\n",
    "    top_and_lower_row = np.concatenate((np.flip(np.flip(img,0),1), np.flip(img,0), np.flip(np.flip(img,0),1)), axis=1)\n",
    "    mid_row = np.concatenate((np.flip(img,1), img, np.flip(img,1)), 1)\n",
    "    \n",
    "    ext_img = np.concatenate((top_and_lower_row, mid_row, top_and_lower_row), 0)\n",
    "       \n",
    "    return ext_img\n",
    "\n",
    "def BuildRotatedImage(img, degree):\n",
    "    \"\"\" Return the same image rataded by <degree> degrees. The corners are filled using mirrored boundaries. \"\"\"\n",
    "    \n",
    "    # Improving performance using existing functions for specific angles\n",
    "    if (degree==0):\n",
    "        return img\n",
    "    elif (degree==90):\n",
    "        return np.rot90(img)\n",
    "    elif (degree==180):\n",
    "        return np.rot90(np.rot90(img))\n",
    "    elif (degree==270):\n",
    "        return np.rot90(np.rot90(np.rot90(img)))\n",
    "    else:\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "\n",
    "        # Extend and rotate the image\n",
    "        ext_img = BuildExtendedImage(img)\n",
    "        rot_img = ndimage.rotate(ext_img, degree, reshape=False)\n",
    "\n",
    "        # Taking care of nummerical accuracies (not sure where they come from)\n",
    "\n",
    "        rot_img[rot_img<0] = 0.0\n",
    "        rot_img[rot_img>1] = 1.0\n",
    "\n",
    "        # Crop the image\n",
    "        if (len(img.shape) > 2):\n",
    "            rot_img = rot_img[h:2*h, w:2*w, :]\n",
    "        else:\n",
    "            rot_img = rot_img[h:2*h, w:2*w]\n",
    "        \n",
    "        return rot_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwXSmDIEi2Vr"
   },
   "outputs": [],
   "source": [
    "# Augmenting the data\n",
    "angles = [0, 90]\n",
    "aug_imgs, aug_gt_imgs = DataAugmentation(imgs, gt_imgs, angles)\n",
    "\n",
    "print(\"(Augmented) number of images (and groundtruth): \", len(aug_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42iG2utmi2Vt"
   },
   "source": [
    "### 3) Extract patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WlIuSy4i2Vu"
   },
   "outputs": [],
   "source": [
    "def img_crop(im, w, h, c=0):\n",
    "    \"\"\" Personalized version of the img_crop incorporating the option of getting the context (c) around the pataches\"\"\"\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    \n",
    "    # padding the image to access the context of border patches\n",
    "    if is_2d:\n",
    "        pad_im = np.pad(im,((c,c),(c,c)), 'reflect')\n",
    "    else:\n",
    "        pad_im = np.pad(im,((c,c),(c,c),(0,0)), 'reflect')\n",
    "\n",
    "    # cropping the image\n",
    "    for i in range(c,imgheight+c,h):\n",
    "        for j in range(c,imgwidth+c,w):\n",
    "            if is_2d:\n",
    "                im_patch = pad_im[j-c:(j+w)+c, i-c:(i+h)+c]\n",
    "            else:\n",
    "                im_patch = pad_im[j-c:(j+w)+c, i-c:(i+h)+c, :]\n",
    "\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def ExtractTrainPatch(imgs, gt_imgs, context=0, balancing=True):\n",
    "    \"\"\" Extract patches of size patch_size from the input images.  \"\"\" \n",
    "    n = len(imgs)\n",
    "    \n",
    "    img_patches = [img_crop(imgs[i], PATCH_SIZE, PATCH_SIZE, context) for i in range(n)]\n",
    "    gt_patches = [img_crop(gt_imgs[i], PATCH_SIZE, PATCH_SIZE) for i in range(n)]\n",
    "\n",
    "\n",
    "    # Linearize list of patches\n",
    "    \n",
    "    X = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "    Y = np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DV_D7odki2Vw"
   },
   "outputs": [],
   "source": [
    "img_patches, gt_patches = ExtractTrainPatch(aug_imgs, aug_gt_imgs, CONTEXT, True)\n",
    "\n",
    "print(\"img_patches has size \", img_patches.shape)\n",
    "print(\"gt_patches has size \", gt_patches.shape)\n",
    "\n",
    "#plt.imshow(img_patches[477], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ht3gqtEdi2Vz"
   },
   "source": [
    "### 4) Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBOGl4g-i2V0"
   },
   "outputs": [],
   "source": [
    "# Extract 6-dimensional features consisting of average RGB color as well as variance\n",
    "def extract_features(img):\n",
    "    feat_m = np.mean(img, axis=(0,1))\n",
    "    feat_v = np.var(img, axis=(0,1))   \n",
    "    features = np.append(feat_m, feat_v)\n",
    "    return features\n",
    "\n",
    "# Extract 2-dimensional features consisting of average gray color as well as variance\n",
    "def extract_features_2d(img):\n",
    "    feat_m = np.mean(img)\n",
    "    feat_v = np.var(img)\n",
    "    feat = np.append(feat_m, feat_v)\n",
    "    return feat\n",
    "\n",
    "# Extract features for a given image\n",
    "def extract_img_features(filename):\n",
    "    img_raw = load_image(filename)\n",
    "    img_patches = img_crop(img, PATCH_SIZE, PATCH_SIZE)\n",
    "    X = np.asarray([extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "    return X, img, img_raw\n",
    "\n",
    "\n",
    "def value_to_class(v, foreground_threshold):\n",
    "    df = np.mean(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def PrintFeatureStatistics(X, Y):\n",
    "    print('There are ' + str(X.shape[0]) + ' data points (patches)')\n",
    "    print('The size of the patches is ' + str(X.shape[1]) + 'x' \n",
    "          + str(X.shape[2]) + ' = ' + str(X.shape[1]*X.shape[2]) +\" pixels\")\n",
    "\n",
    "    print('Number of classes = ' + str(len(np.unique(Y))))\n",
    "\n",
    "    Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "    Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "    print('Class 0 (background): ' + str(len(Y0)) + ' samples')\n",
    "    print('Class 1 (signal): ' + str(len(Y1)) + ' samples')\n",
    "    print('Proportion of road: ', len(Y1)/(len(Y1)+len(Y0)))\n",
    "    print('Proportion of background: ', len(Y0)/(len(Y1)+len(Y0)))\n",
    "\n",
    "def NormalizeFeatures(X):\n",
    "    \"\"\"Normalize X which must have shape (num_data_points,num_features)\"\"\"\n",
    "    m = np.mean(X,axis=0)\n",
    "    s = np.std(X,axis=0)\n",
    "    \n",
    "    return (X-m)/s\n",
    "\n",
    "def Balancing(X_train, Y_train):\n",
    "    c0 = 0  # bgrd\n",
    "    c1 = 0  # road\n",
    "    for i in range(len(Y_train)):\n",
    "        if Y_train[i] == 0:\n",
    "            c0 = c0 + 1\n",
    "        else:\n",
    "            c1 = c1 + 1\n",
    "    print('Number of data points per class (before balancing): c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "    print('Balancing training data...')\n",
    "    min_c = min(c0, c1)\n",
    "    idx0 = [i for i in range(len(Y_train)) if Y_train[i] == 0]\n",
    "    idx1 = [i for i in range(len(Y_train)) if Y_train[i] == 1]\n",
    "    indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "    new_indices = np.random.permutation(indices)\n",
    "    \n",
    "    X_balanced = X_train[new_indices]\n",
    "    Y_balanced = Y_train[new_indices]\n",
    "\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    for i in range(len(Y_balanced)):\n",
    "        if Y_balanced[i] == 0:\n",
    "            c0 = c0 + 1\n",
    "        else:\n",
    "            c1 = c1 + 1\n",
    "    print('Number of data points per class (after balancing): c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "    \n",
    "    return X_balanced, Y_balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBjGEebmi2V3"
   },
   "outputs": [],
   "source": [
    "# Compute features for each image patch\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "#X = np.asarray([extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "X_tr_raw = np.copy(img_patches)\n",
    "Y_tr_raw = np.asarray([value_to_class(gt_patches[i], foreground_threshold) for i in range(len(gt_patches))])\n",
    "\n",
    "X_tr_bal, Y_tr_bal = Balancing(X_tr_raw, Y_tr_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jq5sk8zi2V-"
   },
   "outputs": [],
   "source": [
    "# Print feature statistics\n",
    "PrintFeatureStatistics(X_tr_bal, Y_tr_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4-fcwcCi2WB"
   },
   "source": [
    "### 5) CNN model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5CrqFKGi2WC"
   },
   "outputs": [],
   "source": [
    "# Convert array of labels to an image\n",
    "\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    im = np.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            im[j:j+w, i:i+h] = labels[idx]\n",
    "            idx = idx + 1\n",
    "    return im\n",
    "\n",
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img\n",
    "\n",
    "def TruePositiveRate(tX, Y, logregModel):\n",
    "    \"\"\"Compute the true positive rate of the lgistic regression model logregModel on \n",
    "       the training augmented data tX.\n",
    "    \"\"\"\n",
    "    # Predict on the training set\n",
    "    Y_pred = logregModel.predict(tX)\n",
    "    \n",
    "    # Get non-zeros in prediction and grountruth arrays\n",
    "    Y_predn = np.nonzero(Y_pred)[0]\n",
    "    Yn = np.nonzero(Y)[0]\n",
    "\n",
    "    TPR = len(list(set(Yn) & set(Y_predn))) / float(len(Yn))\n",
    "    return TPR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Zu76OBEi2WD"
   },
   "outputs": [],
   "source": [
    "# number of convolutional filters to use\n",
    "nb_filters1 = 128\n",
    "nb_filters2 = 64\n",
    "nb_filters3 = 32\n",
    "\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "\n",
    "# convolution kernel size\n",
    "kernel_size = (5, 5)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_tr = np_utils.to_categorical(Y_tr_bal, NB_CLASSES)\n",
    "\n",
    "# normalizing the training data\n",
    "#X_tr = tf.keras.utils.normalize(X_tr_bal, axis=(1,2)) # TODO\n",
    "X_tr = np.copy(X_tr_bal).astype('float32')\n",
    "\n",
    "# input size\n",
    "input_shape = (X_tr.shape[1], X_tr.shape[2], X_tr.shape[3])\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters1, kernel_size, padding='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, kernel_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, kernel_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiGdV-lBi2WE"
   },
   "outputs": [],
   "source": [
    "#Deleting unused variables\n",
    "#del X_tr_bal, X_tr_raw, Y_tr_bal, Y_tr_raw, imgs, gt_imgs, img_patches, gt_patches, aug_imgs, aug_gt_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqAT_GPAi2WF"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, Y_tr, batch_size=BATCH_SIZE, epochs=NB_EPOCHS, verbose=2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_s1KI8Gi2WK"
   },
   "source": [
    "### 6) CNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2lfmxrQi2WK"
   },
   "outputs": [],
   "source": [
    "def PlotHistory(history):\n",
    "      # Plot training & validation accuracy values\n",
    "\n",
    "      plt.plot(history.history['acc'])\n",
    "      plt.plot(history.history['val_acc'])\n",
    "      plt.title('Model accuracy')\n",
    "      plt.ylabel('Accuracy')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.legend(['Train', 'Test'], loc='upper left')\n",
    "      plt.show()\n",
    "\n",
    "      # Plot training & validation loss values\n",
    "      plt.plot(history.history['loss'])\n",
    "      plt.plot(history.history['val_loss'])\n",
    "      plt.title('Model loss')\n",
    "      plt.ylabel('Loss')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.legend(['Train', 'Test'], loc='upper left')\n",
    "      plt.show()\n",
    "\n",
    "      score = model.evaluate(X_tr, Y_tr, verbose=0)\n",
    "      print('Test score:', score[0])\n",
    "      print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bym9qDji2WM"
   },
   "outputs": [],
   "source": [
    "def binary_to_uint8(img):\n",
    "    rimg = (img * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "def reconstruct_from_labels(image_id, submissionfile):\n",
    "    im = np.zeros((imgwidth, imgheight), dtype=np.uint8)\n",
    "    f = open(submissionfile)\n",
    "    lines = f.readlines()\n",
    "    image_id_str = \"%.3d_\" % image_id\n",
    "    for i in range(1, len(lines)):\n",
    "        line = lines[i]\n",
    "        if not image_id_str in line:\n",
    "            continue\n",
    "\n",
    "        tokens = line.split(\",\")\n",
    "        id = tokens[0]\n",
    "        prediction = int(tokens[1])\n",
    "        tokens = id.split(\"_\")\n",
    "        i = int(tokens[1])\n",
    "        j = int(tokens[2])\n",
    "\n",
    "        je = min(j + w, imgwidth)\n",
    "        ie = min(i + h, imgheight)\n",
    "        if prediction == 0:\n",
    "            adata = np.zeros((w, h))\n",
    "        else:\n",
    "            adata = np.ones((w, h))\n",
    "\n",
    "        im[j:je, i:ie] = binary_to_uint8(adata)\n",
    "\n",
    "    Image.fromarray(im).save(\"prediction_\" + \"%.3d\" % image_id + \".png\")\n",
    "\n",
    "    return im\n",
    "\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i : i + patch_size, j : j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield (\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, \"w\") as f:\n",
    "        f.write(\"id,prediction\\n\")\n",
    "        for fn in image_filenames:\n",
    "            f.writelines(\"{}\\n\".format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "def ExtractTestPatch(img, context=0):\n",
    "    \"\"\" Extract patches of size patch_size from the input image.\"\"\" \n",
    "\n",
    "\n",
    "    img_patches = img_crop(img, PATCH_SIZE, PATCH_SIZE, context)\n",
    "    \n",
    "    # Linearize list of patches\n",
    "    img_patches = np.asarray([img_patches[i]\n",
    "                              for i in range(len(img_patches))])\n",
    "    return img_patches\n",
    "\n",
    "def CreateSubmission(CNNmodel):\n",
    "    \"\"\" Create a submission file using the trained logregModel.\"\"\"\n",
    "    # paths\n",
    "    test_rootdir = DATA_ROOT_DIR + \"test_set_images/\"\n",
    "    test_files = os.listdir(test_rootdir)\n",
    "    \n",
    "    prediction_filenames = []\n",
    "    \n",
    "    # Prediction of all the test images\n",
    "    for i  in range(len(test_files)):\n",
    "        print(\"Predicting image\" + test_files[i] + \"...\")\n",
    "        # Image path of the i-th image\n",
    "        img_path = test_rootdir + test_files[i] + \"/\" + test_files[i] + \".png\"\n",
    "        \n",
    "        # Extraction of the data feature\n",
    "        img = load_image(img_path)\n",
    "        Xi = ExtractTestPatch(img, CONTEXT)\n",
    "        \n",
    "        # Prediction of the i-th image using the trained model logregModel\n",
    "        Yi_prob = CNNmodel.predict(Xi, verbose=0)\n",
    "        Yi_pred = np.argmax(Yi_prob, axis=1)\n",
    "        \n",
    "        # Construction of the mask\n",
    "        w = img.shape[0]\n",
    "        h = img.shape[1]\n",
    "        predicted_mask = label_to_img(w, h, PATCH_SIZE, PATCH_SIZE, Yi_pred)\n",
    "        \n",
    "        # Creating the name for the predicted mask\n",
    "        img_id = int(re.search(r\"\\d+\", test_files[i]).group(0))\n",
    "        prediction_filenames += [PREDICTION_DIR + \"prediction_\" + \"%.3d\" % img_id + \".png\"]\n",
    "        \n",
    "        # Saving the masks in the preddir folder\n",
    "        Image.fromarray(binary_to_uint8(predicted_mask)).save(prediction_filenames[i])  \n",
    "    \n",
    "    # Create unique filename\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%H_%M__%d_%m\")\n",
    "    submission_filename = SUBMISSION_DIR + \"submission_CNN_\" + dt_string + \".csv\"\n",
    "    \n",
    "    # Create submission\n",
    "    print(\"Creating submission file...\")\n",
    "    masks_to_submission(submission_filename, prediction_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDt9bqBpi2WN"
   },
   "outputs": [],
   "source": [
    "CreateSubmission(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuYLNr4oi2WO"
   },
   "outputs": [],
   "source": [
    "def VisualizeCNNPrediction(CNNModel, img_ind):\n",
    "    \n",
    "    test_rootdir = DATA_ROOT_DIR + \"test_set_images/\"\n",
    "    test_files = os.listdir(test_rootdir)\n",
    "    img_path = test_rootdir + test_files[img_ind] + \"/\" + test_files[img_ind] + \".png\"\n",
    "    \n",
    "    img = load_image(img_path)\n",
    "    Xi = ExtractTestPatch(img, CONTEXT)\n",
    "    Yi_prob = CNNModel.predict(Xi, verbose=0)\n",
    "    Yi_pred = np.argmax(Yi_prob, axis=1)\n",
    "    print(\"Number of predicted road patches: \", Yi_pred.sum())\n",
    "    # Display prediction as an image\n",
    "\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    predicted_im = label_to_img(w, h, PATCH_SIZE, PATCH_SIZE, Yi_pred)\n",
    "    cimg = make_img_overlay(img, predicted_im)\n",
    "    fig1 = plt.figure(figsize=(8, 4)) \n",
    "    fig1.suptitle(img_path + \"\\nImage (left) and prediction (right)\")\n",
    "    plt.imshow(cimg, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFGh3wimi2WP"
   },
   "outputs": [],
   "source": [
    "VisualizeCNNPrediction(model, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kV-KonUVi2WQ"
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CNN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
