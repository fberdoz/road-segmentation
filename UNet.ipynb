{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxR5rbti2VV"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, re\n",
    "from PIL import Image                                 #create image from array\n",
    "from datetime import datetime                         #date for submission file\n",
    "from  scipy import ndimage\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# CNN libraries (keras)\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#For Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vU5YEHpi2Vc"
   },
   "outputs": [],
   "source": [
    "SEED = 1642\n",
    "PATCH_SIZE = 16\n",
    "NUMBER_TRAIN_IMG = 100 # max 100\n",
    "ROOT = './'\n",
    "DATA_ROOT_DIR = ROOT+ \"Datasets/\"\n",
    "SUBMISSION_DIR = ROOT + \"Submissions/\"\n",
    "PREDICTION_DIR = ROOT + \"Predictions/\"\n",
    "CHECKPOINT_DIR = ROOT + 'Checkpoints/'\n",
    "NB_CLASSES = 2\n",
    "NB_EPOCHS = 200\n",
    "BATCH_SIZE = 20\n",
    "FOREGROUND_THRESHOLD = 0.25\n",
    "FOREGROUND_THRESHOLD_R = 0.25 # for recontruction\n",
    "\n",
    "IMG_SIZE = 608\n",
    "PAD = int((IMG_SIZE - 400)/2)\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "np.random.seed(SEED)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "in8-_6-jyMj5",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def LoadTrainingData(n_img, rootdir=\"Datasets/training/\", printnames=False):\n",
    "    \"\"\" Load the data from the root directory. (a total of n_img images) \"\"\"\n",
    "\n",
    "    image_dir = rootdir + \"images/\"\n",
    "    files = os.listdir(image_dir)\n",
    "\n",
    "    n = min(n_img, len(files)) # Load maximum 20 images\n",
    "    print(\"Loading \" + str(n) + \" train images...\")\n",
    "    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    gt_dir = rootdir + \"groundtruth/\"\n",
    "    print(\"Loading \" + str(n) + \" groundtruth images...\")\n",
    "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    if (printnames):\n",
    "        print(\"The loaded images are: \")\n",
    "        for i in range(n):\n",
    "            print(\"    - \" + files[i])\n",
    "    \n",
    "    return imgs, gt_imgs\n",
    "\n",
    "def DataAugmentation(imgs, gt_imgs, angles, sym=False, printinfo=False):\n",
    "    \"\"\"\n",
    "    Augments the data by rotating the image with the angles given in the list <angles>.\n",
    "    If <sym> is true, it also augments the the data with the images obtained by performing a\n",
    "    y axis symmetry.\n",
    "    \n",
    "    The augmented data will present itself as follows: \n",
    "        \n",
    "        [angles[1] rotations, ..., angles[end] rotations,\n",
    "        Y axis symmetry of the angles[1] rotations, ..., Y axis symmetry of the angles[end] rotations]\n",
    " \n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    \n",
    "    # Creating the augmented version of the images.\n",
    "    aug_imgs = []\n",
    "    aug_gt_imgs = []\n",
    "    \n",
    "    # Rotating the images and adding them to the augmented data list\n",
    "    for theta in angles:\n",
    "        if (printinfo):\n",
    "            print(\"Augmenting the data with the images rotated by\", theta , \"deg.\")\n",
    "        aug_imgs += [BuildRotatedImage(imgs[i], theta) for i in range(n)]\n",
    "        aug_gt_imgs += [BuildRotatedImage(gt_imgs[i], theta) for i in range(n)]  \n",
    "        \n",
    "    # Y symmetry of the images and adding them to the augmented dat list\n",
    "    if (sym):\n",
    "        if (printinfo):\n",
    "            print(\"Augmenting the data with the symmetries\")\n",
    "        n_tmp = len(aug_imgs)\n",
    "        aug_imgs += [np.flip(aug_imgs[i],1) for i in range(n_tmp)]\n",
    "        aug_gt_imgs += [np.flip(aug_gt_imgs[i],1) for i in range(n_tmp)]\n",
    "        \n",
    "    return aug_imgs, aug_gt_imgs\n",
    "\n",
    "\n",
    "def BuildExtendedImage(img, pad):\n",
    "    \"\"\" Create a 3x3 grid of the imput image by mirroring it at the boundaries\"\"\"\n",
    "    \n",
    "    ext_img = cv2.copyMakeBorder(img, pad, pad, pad, pad, cv2.BORDER_REFLECT) \n",
    "\n",
    "    return ext_img\n",
    "\n",
    "def BuildRotatedImage(img, degree):\n",
    "    \"\"\" Return the same image rataded by <degree> degrees. The corners are filled using mirrored boundaries. \"\"\"\n",
    "    \n",
    "    # Improving performance using existing functions for specific angles\n",
    "    if (degree==0):\n",
    "        return img\n",
    "    elif (degree==90):\n",
    "        return np.rot90(img)\n",
    "    elif (degree==180):\n",
    "        return np.rot90(np.rot90(img))\n",
    "    elif (degree==270):\n",
    "        return np.rot90(np.rot90(np.rot90(img)))\n",
    "    else:\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "\n",
    "        padh = math.ceil(h/4)\n",
    "        padw = math.ceil(w/4)\n",
    "        pad = max(padh, padw)\n",
    "\n",
    "\n",
    "        # Extend and rotate the image\n",
    "        ext_img = BuildExtendedImage(img, pad)\n",
    "        rot_img = ndimage.rotate(ext_img, degree, reshape=False)\n",
    "\n",
    "        # Taking care of nummerical accuracies (not sure where they come from)\n",
    "\n",
    "        rot_img[rot_img<0] = 0.0\n",
    "        rot_img[rot_img>1] = 1.0\n",
    "\n",
    "        # Crop the image\n",
    "        if (len(img.shape) > 2):\n",
    "            rot_img = rot_img[pad:pad+h, pad:pad+w, :]\n",
    "        else:\n",
    "            rot_img = rot_img[pad:pad+h, pad:pad+w]\n",
    "        \n",
    "        return rot_img\n",
    "\n",
    "def img_crop(im, w, h, c=0):\n",
    "    \"\"\" Personalized version of the img_crop incorporating the option of getting the context (c) around the pataches\"\"\"\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    \n",
    "    # padding the image to access the context of border patches\n",
    "    if is_2d:\n",
    "        pad_im = np.pad(im,((c,c),(c,c)), 'reflect')\n",
    "    else:\n",
    "        pad_im = np.pad(im,((c,c),(c,c),(0,0)), 'reflect')\n",
    "\n",
    "    # cropping the image\n",
    "    for i in range(c,imgheight+c,h):\n",
    "        for j in range(c,imgwidth+c,w):\n",
    "            if is_2d:\n",
    "                im_patch = pad_im[j-c:(j+w)+c, i-c:(i+h)+c]\n",
    "            else:\n",
    "                im_patch = pad_im[j-c:(j+w)+c, i-c:(i+h)+c, :]\n",
    "\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def ExtractTrainPatch(imgs, gt_imgs, context=0, balancing=True):\n",
    "    \"\"\" Extract patches of size patch_size from the input images.  \"\"\" \n",
    "    n = len(imgs)\n",
    "    \n",
    "    img_patches = [img_crop(imgs[i], PATCH_SIZE, PATCH_SIZE, context) for i in range(n)]\n",
    "    gt_patches = [img_crop(gt_imgs[i], PATCH_SIZE, PATCH_SIZE) for i in range(n)]\n",
    "\n",
    "    # Linearize list of patches\n",
    "    \n",
    "    X = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "    Y = np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.mean(v)\n",
    "    if df > FOREGROUND_THRESHOLD:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > FOREGROUND_THRESHOLD_R:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def PrintFeatureStatistics(X, Y):\n",
    "    print('There are ' + str(X.shape[0]) + ' data points (patches)')\n",
    "    print('The size of the patches is ' + str(X.shape[1]) + 'x' \n",
    "          + str(X.shape[2]) + ' = ' + str(X.shape[1]*X.shape[2]) +\" pixels\")\n",
    "\n",
    "    print('Number of classes = ' + str(len(np.unique(Y))))\n",
    "\n",
    "    Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "    Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "    print('Class 0 (background): ' + str(len(Y0)) + ' samples')\n",
    "    print('Class 1 (signal): ' + str(len(Y1)) + ' samples')\n",
    "    print('Proportion of road: ', len(Y1)/(len(Y1)+len(Y0)))\n",
    "    print('Proportion of background: ', len(Y0)/(len(Y1)+len(Y0)))\n",
    "\n",
    "def NormalizeFeatures(X):\n",
    "    \"\"\"Normalize X which must have shape (num_data_points,num_features)\"\"\"\n",
    "    m = np.mean(X,axis=0)\n",
    "    s = np.std(X,axis=0)\n",
    "    \n",
    "    return (X-m)/s\n",
    "\n",
    "def Balancing(X_train, Y_train):\n",
    "    c0 = 0  # bgrd\n",
    "    c1 = 0  # road\n",
    "    for i in range(len(Y_train)):\n",
    "        if Y_train[i] == 0:\n",
    "            c0 = c0 + 1\n",
    "        else:\n",
    "            c1 = c1 + 1\n",
    "    print('Number of data points per class (before balancing): background = ' + str(c0) + ' road = ' + str(c1))\n",
    "\n",
    "    print('Balancing training data...')\n",
    "    min_c = min(c0, c1)\n",
    "    idx0 = [i for i in range(len(Y_train)) if Y_train[i] == 0]\n",
    "    idx1 = [i for i in range(len(Y_train)) if Y_train[i] == 1]\n",
    "    indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "    new_indices = np.random.permutation(indices)\n",
    "    \n",
    "    X_balanced = X_train[new_indices]\n",
    "    Y_balanced = Y_train[new_indices]\n",
    "\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    for i in range(len(Y_balanced)):\n",
    "        if Y_balanced[i] == 0:\n",
    "            c0 = c0 + 1\n",
    "        else:\n",
    "            c1 = c1 + 1\n",
    "    print('Number of data points per class (after balancing): background = ' + str(c0) + ' road = ' + str(c1))\n",
    "    \n",
    "    return X_balanced, Y_balanced\n",
    "\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    im = np.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            im[j:j+w, i:i+h] = labels[idx]\n",
    "            idx = idx + 1\n",
    "    return im\n",
    "\n",
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*255\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img\n",
    "\n",
    "def TruePositiveRate(tX, Y, logregModel):\n",
    "    \"\"\"Compute the true positive rate of the lgistic regression model logregModel on \n",
    "       the training augmented data tX.\n",
    "    \"\"\"\n",
    "    # Predict on the training set\n",
    "    Y_pred = logregModel.predict(tX)\n",
    "    \n",
    "    # Get non-zeros in prediction and grountruth arrays\n",
    "    Y_predn = np.nonzero(Y_pred)[0]\n",
    "    Yn = np.nonzero(Y)[0]\n",
    "\n",
    "    TPR = len(list(set(Yn) & set(Y_predn))) / float(len(Yn))\n",
    "    return TPR\n",
    "    \n",
    "def Normalize(X, axis=(0,1,2)):\n",
    "\n",
    "    m = np.mean(X, axis)\n",
    "    s = np.std(X, axis)\n",
    "    print(\"Mean before normalization: \", m)\n",
    "    print(\"Std before normalization: \", s)\n",
    "\n",
    "    X_norm = (X - m)/s\n",
    "    print(\"Mean after normalization: \", np.mean(X_norm, axis))\n",
    "    print(\"Std after normalization: \", np.std(X_norm, axis))\n",
    "    return X_norm\n",
    "\n",
    "\n",
    "def PlotHistory(history):\n",
    "    # Plot training & validation accuracy values\n",
    "\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    score = model.evaluate(X_tr, Y_tr, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "def VisualizeUNETPrediction(UNETModel, img_ind):\n",
    "    \n",
    "    test_rootdir = DATA_ROOT_DIR + \"test_set_images/\"\n",
    "    test_files = os.listdir(test_rootdir)\n",
    "    img_path = test_rootdir + test_files[img_ind] + \"/\" + test_files[img_ind] + \".png\"\n",
    "    \n",
    "    # Extraction of the data feature\n",
    "    Xi = load_image(img_path)\n",
    "    \n",
    "    # Prediction of the i-th image using the trained model logregModel\n",
    "    Yi_prob = UNETModel.predict(np.expand_dims(Xi, axis=0), verbose=0).squeeze()\n",
    "    \n",
    "    gt_patches = img_crop(Yi_prob, PATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "    Yi_pred = np.asarray([patch_to_label(gt_patches[i]) for i in range(len(gt_patches))])\n",
    "    \n",
    "    # Construction of the mask\n",
    "    w = Xi.shape[0]\n",
    "    h = Xi.shape[1]\n",
    "    predicted_mask = label_to_img(w, h, PATCH_SIZE, PATCH_SIZE, Yi_pred)\n",
    "\n",
    "    cimg = make_img_overlay(Xi, predicted_mask)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax1.imshow(cimg, cmap='Greys_r')\n",
    "    ax1.set_title(\"U-Net prediction\")\n",
    "    ax2.imshow(Yi_prob, cmap='Greys_r')\n",
    "    ax2.set_title(\"U-Net mask\")\n",
    "    fig.suptitle(\"U-Net\")\n",
    "\n",
    "def binary_to_uint8(img):\n",
    "    rimg = (img * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "def reconstruct_from_labels(image_id, submissionfile):\n",
    "    im = np.zeros((imgwidth, imgheight), dtype=np.uint8)\n",
    "    f = open(submissionfile)\n",
    "    lines = f.readlines()\n",
    "    image_id_str = \"%.3d_\" % image_id\n",
    "    for i in range(1, len(lines)):\n",
    "        line = lines[i]\n",
    "        if not image_id_str in line:\n",
    "            continue\n",
    "\n",
    "        tokens = line.split(\",\")\n",
    "        id = tokens[0]\n",
    "        prediction = int(tokens[1])\n",
    "        tokens = id.split(\"_\")\n",
    "        i = int(tokens[1])\n",
    "        j = int(tokens[2])\n",
    "\n",
    "        je = min(j + w, imgwidth)\n",
    "        ie = min(i + h, imgheight)\n",
    "        if prediction == 0:\n",
    "            adata = np.zeros((w, h))\n",
    "        else:\n",
    "            adata = np.ones((w, h))\n",
    "\n",
    "        im[j:je, i:ie] = binary_to_uint8(adata)\n",
    "\n",
    "    Image.fromarray(im).save(\"prediction_\" + \"%.3d\" % image_id + \".png\")\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i : i + patch_size, j : j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield (\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, \"w\") as f:\n",
    "        f.write(\"id,prediction\\n\")\n",
    "        for fn in image_filenames:\n",
    "            f.writelines(\"{}\\n\".format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "def ExtractTestPatch(img, context=0):\n",
    "    \"\"\" Extract patches of size patch_size from the input image.\"\"\" \n",
    "\n",
    "\n",
    "    img_patches = img_crop(img, PATCH_SIZE, PATCH_SIZE, context)\n",
    "    \n",
    "    # Linearize list of patches\n",
    "    img_patches = np.asarray([img_patches[i]\n",
    "                              for i in range(len(img_patches))])\n",
    "    return img_patches\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_true[y_true >= FOREGROUND_THRESHOLD_R] = 1\n",
    "    y_true[y_true < FOREGROUND_THRESHOLD_R] = 0\n",
    "\n",
    "    y_pred[y_pred >= FOREGROUND_THRESHOLD_R] = 1\n",
    "    y_pred[y_pred < FOREGROUND_THRESHOLD_R] = 0\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "def CreateSubmissionUNET(UNETmodel):\n",
    "    \"\"\" Create a submission file using the trained logregModel.\"\"\"\n",
    "    # paths\n",
    "    test_rootdir = DATA_ROOT_DIR + \"test_set_images/\"\n",
    "    test_files = os.listdir(test_rootdir)\n",
    "    \n",
    "    prediction_filenames = []\n",
    "    \n",
    "    # Prediction of all the test images\n",
    "    for i  in range(len(test_files)):\n",
    "        print(\"Predicting image\" + test_files[i] + \"...\")\n",
    "        # Image path of the i-th image\n",
    "        img_path = test_rootdir + test_files[i] + \"/\" + test_files[i] + \".png\"\n",
    "        \n",
    "        # Extraction of the data feature\n",
    "        Xi = load_image(img_path)\n",
    "        \n",
    "        # Prediction of the i-th image using the trained model logregModel\n",
    "        Yi_prob = UNETmodel.predict(np.expand_dims(Xi, axis=0), verbose=0).squeeze()\n",
    "        gt_patches = img_crop(Yi_prob, PATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "        Yi_pred = np.asarray([patch_to_label(gt_patches[i]) for i in range(len(gt_patches))])\n",
    "        \n",
    "        # Construction of the mask\n",
    "        w = Xi.shape[0]\n",
    "        h = Xi.shape[1]\n",
    "        predicted_mask = label_to_img(w, h, PATCH_SIZE, PATCH_SIZE, Yi_pred)\n",
    "        \n",
    "        # Creating the name for the predicted mask\n",
    "        img_id = int(re.search(r\"\\d+\", test_files[i]).group(0))\n",
    "        prediction_filenames += [PREDICTION_DIR + \"prediction_\" + \"%.3d\" % img_id + \".png\"]\n",
    "        \n",
    "        # Saving the masks in the preddir folder\n",
    "        Image.fromarray(binary_to_uint8(predicted_mask)).save(prediction_filenames[i])  \n",
    "    \n",
    "    # Create unique filename\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%H_%M-%d_%m')\n",
    "\n",
    "    # Create a folder in the submssion directory and save the submission and the model in it\n",
    "    os.mkdir(SUBMISSION_DIR + dt_string)\n",
    "    model.save(SUBMISSION_DIR + dt_string + '/' + 'modelUNET.h5')\n",
    "\n",
    "    submission_filename = SUBMISSION_DIR  + dt_string + '/' + 'submission_UNET_' + dt_string + '.csv'\n",
    "    \n",
    "    # Create submission\n",
    "    print(\"Creating submission file...\")\n",
    "    masks_to_submission(submission_filename, prediction_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0iLMJedei2Vf"
   },
   "source": [
    "### 1) Loading the set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iow463wPi2Vj"
   },
   "outputs": [],
   "source": [
    "traindir = DATA_ROOT_DIR + \"training/\"\n",
    "imagedir = traindir + \"images/\"\n",
    "\n",
    "# list with all the available images name\n",
    "files = os.listdir(imagedir) \n",
    "\n",
    "n = NUMBER_TRAIN_IMG\n",
    "imgs, gt_imgs = LoadTrainingData(n, traindir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxIkMnAFi2Vm"
   },
   "source": [
    "### 2) Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwXSmDIEi2Vr"
   },
   "outputs": [],
   "source": [
    "# Augmenting the data\n",
    "angles = [0, 30, 45, 60, 90, 120, 135, 150, 180]\n",
    "aug_imgs_small, aug_gt_imgs_small = DataAugmentation(imgs, gt_imgs, angles, sym=True, printinfo=True)\n",
    "\n",
    "X_tr = np.asarray([BuildExtendedImage(aug_imgs_small[i], PAD) for i in range(len(aug_imgs_small))])\n",
    "Y_tr_raw = np.asarray([BuildExtendedImage(aug_gt_imgs_small[i], PAD) for i in range(len(aug_gt_imgs_small))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrX1D8ah_xyq"
   },
   "outputs": [],
   "source": [
    "# deleting unused variables\n",
    "del imgs, gt_imgs, aug_imgs_small, aug_gt_imgs_small\n",
    "\n",
    "print(\"(Augmented) number of images (and groundtruth): \", X_tr.shape[0])\n",
    "#plt.imshow(X_tr[100], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1bda34R3Oz4"
   },
   "outputs": [],
   "source": [
    "# processing the training data\n",
    "X_tr = X_tr.astype('float32')\n",
    "Y_tr = np.expand_dims(Y_tr_raw, axis=3).astype('float32')\n",
    "\n",
    "print(\" Shape of X_tr: \", X_tr.shape)\n",
    "print(\" Shape of Y_tr: \", Y_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4-fcwcCi2WB"
   },
   "source": [
    "### 3) CNN model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mg8VhD4RClpw",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, IMG_CHANNELS))\n",
    "\n",
    "s = tf.keras.layers.Lambda(lambda x: x )(inputs)\n",
    " \n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    " \n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c5)\n",
    " \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c9)\n",
    " \n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    " \n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNdQr2PCypxV"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqAT_GPAi2WF"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(CHECKPOINT_DIR + 'UNET_V2.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "history = model.fit(X_tr, Y_tr, batch_size=BATCH_SIZE, epochs=NB_EPOCHS, validation_split = 0.20, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_s1KI8Gi2WK"
   },
   "source": [
    "### 5) Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2lfmxrQi2WK"
   },
   "outputs": [],
   "source": [
    "# Trainign history\n",
    "PlotHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDt9bqBpi2WN"
   },
   "outputs": [],
   "source": [
    "# Create a submission\n",
    "CreateSubmissionUNET(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFGh3wimi2WP"
   },
   "outputs": [],
   "source": [
    "# Visualize a prediction\n",
    "VisualizeUNETPrediction(model, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kV-KonUVi2WQ"
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNet.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
